
# Sentiment Analysis API

## Description
Ce projet permet d'analyser les sentiments des tweets √† l'aide d'une API Flask, d'une base de donn√©es MySQL et d'un mod√®le de r√©gression logistique entra√Æn√© avec `scikit-learn`.

---

## Pr√©requis
Avant de commencer, assurez-vous d'avoir install√© les outils suivants :
- **Python 3.9+**
- **Docker et Docker Compose**
- **Git**

---

## Installation du Projet

### 1. **Cloner le d√©p√¥t**
Clonez ce projet sur votre machine :
```bash
git clone <URL_DU_DEPOT>
cd sentiment-analysis-api
```

### 2. **Configurer l'environnement Python**
Cr√©ez un environnement virtuel et installez les d√©pendances :
```bash
python3 -m venv venv
source venv/bin/activate          # Sous Windows : venv\Scripts\activate
pip install -r requirements.txt
```

### 3. **Configurer Docker**
Lancez la base de donn√©es MySQL avec Docker :
```bash
docker-compose up -d
```

V√©rifiez que le conteneur MySQL est bien en cours d'ex√©cution :
```bash
docker ps
```

### 4. **Cr√©er le fichier `.env`**
Cr√©ez un fichier `.env` √† la racine du projet pour stocker les variables d'environnement :
```
MYSQL_HOST=localhost
MYSQL_PORT=3306
MYSQL_USER=sentiment_user
MYSQL_PASSWORD=user_password
MYSQL_DB=sentiment_db
FLASK_ENV=development
```

### 5. **Initialiser la base de donn√©es**
Cr√©ez la table `tweets` dans la base de donn√©es :
```bash
python -m app.database create_table
```

### 6. **Tester la base de donn√©es**
Pour voir les donn√©es (s'il y en a) dans la table `tweets` :
```bash
python -m app.database fetch_tweets
```

---

## Utilisation

### 1. **Lancer l'API Flask**
Activez l'environnement virtuel (si ce n'est pas encore fait) et lancez le serveur Flask :
```bash
source venv/Scripts/activate          # Sous Windows : venv\Scripts\activate
python app/api.py
```

L'API sera disponible sur [http://127.0.0.1:5000](http://127.0.0.1:5000).

### 2. **Endpoint d'Analyse des Sentiments**
Utilisez un client HTTP comme **Postman** ou **curl** pour interagir avec l'API.

#### Exemple de requ√™te :
```bash
curl -X POST http://127.0.0.1:5000/analyze \
-H "Content-Type: application/json" \
-d '{
    "tweets": ["J'adore ce projet !", "Ce programme est horrible..."]
}'
```

#### Exemple de r√©ponse :
```json
{
    "tweet1": 0.8,
    "tweet2": -0.6
}
```


### 3. **R√©cup√©rer tous les tweets enregistr√©s**
L'endpoint `GET /tweets` permet de r√©cup√©rer tous les tweets enregistr√©s dans la base de donn√©es.

#### Exemple de requ√™te :
```bash
curl http://127.0.0.1:5000/tweets
```

#### Exemple de r√©ponse :
```json
[
    {
        "id": 1,
        "text": "J'adore ce projet !",
        "positive": 1,
        "negative": 0
    },
    {
        "id": 2,
        "text": "Ce programme est horrible...",
        "positive": 0,
        "negative": 1
    }
]
```

Cet endpoint est utile pour v√©rifier les tweets d√©j√† analys√©s et enregistr√©s dans la base.


---

## Scripts Disponibles

### Initialiser la base de donn√©es
Cr√©er la table `tweets` :
```bash
python -m app.database create_table
```

### üìå Stockage des Tweets en Base de Donn√©es
- **Tous les tweets analys√©s** via `/analyze` sont **automatiquement enregistr√©s** dans la base MySQL.
- La table **`tweets`** contient :
  - `id` (cl√© primaire)
  - `text` (contenu du tweet)
  - `positive` (1 = positif, 0 = n√©gatif)
  - `negative` (1 = n√©gatif, 0 = positif)

Cela permet de **r√©entra√Æner le mod√®le** uniquement sur de nouvelles donn√©es au fil du temps.

### Voir les donn√©es de la base de donn√©es
Afficher les entr√©es existantes dans la table `tweets` :
```bash
python -m app.database fetch_tweets
```

### R√©entra√Ænement Automatique
Lors du d√©marrage de l'API, elle v√©rifie si un r√©entra√Ænement du mod√®le est n√©cessaire.
- Si le dernier r√©entra√Ænement date de **plus de 7 jours**, un nouveau r√©entra√Ænement est lanc√© automatiquement.
- Les logs de r√©entra√Ænement sont stock√©s dans la table **`retraining_logs`**.

 Vous pouvez √©galement le lancer manuellement :
```bash
python -m app.api retrain_model
```
---

### üìå Mod√®le de Classification Utilis√©
Nous utilisons **`LogisticRegression`** avec **`CountVectorizer()`** pour transformer les textes en vecteurs num√©riques.
#### üí° Am√©liorations possibles :
- Tester **`TfidfVectorizer()`** pour donner plus d'importance aux mots rares.
- Essayer **`RandomForestClassifier`** pour une meilleure robustesse.
- Ajouter **plus de tweets positifs** pour √©quilibrer les donn√©es d'entra√Ænement.

---